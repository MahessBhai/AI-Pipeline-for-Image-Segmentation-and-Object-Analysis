import torch
import torchvision
import numpy as np
import matplotlib.pyplot as plt
import cv2
import os
import uuid
from PIL import Image
import json
from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor

class ImageSegmentationPipeline:
    def __init__(self, sam_checkpoint, model_type='vit_h', output_dir='segmented_objects'):
        """
        Initializes the ImageSegmentationPipeline with the SAM model and output directory.

        Parameters:
        - sam_checkpoint: Path to the SAM model checkpoint file.
        - model_type: Type of SAM model to use (default is 'vit_h').
        - output_dir: Default directory to save segmented objects and metadata.
        """
        self.sam_checkpoint = sam_checkpoint
        self.model_type = model_type
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available
        self.output_dir = output_dir
        self.sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)  # Load SAM model
        self.sam.to(device=self.device)  # Move model to the appropriate device (GPU/CPU)
        self.mask_generator = SamAutomaticMaskGenerator(
            model=self.sam,
            points_per_side=32,
            pred_iou_thresh=0.95,
            stability_score_thresh=0.95,
            crop_n_layers=1,
            box_nms_thresh=0.6,
            crop_n_points_downscale_factor=20,
            min_mask_region_area=400  # Requires OpenCV for post-processing
        )
        os.makedirs(self.output_dir, exist_ok=True)  # Create output directory if it doesn't exist

    def extract_and_save_objects(self, image, masks, master_id, output_dir):
        """
        Extracts objects from an image using the provided masks and saves them as separate images.

        Parameters:
        - image: The original image from which objects are extracted.
        - masks: A list of masks generated by the SAM model.
        - master_id: A unique identifier for the original image and its objects.
        - output_dir: Directory to save the extracted objects and metadata.

        Returns:
        - object_data: A list of metadata dictionaries for each extracted object.
        """
        image_output_dir = os.path.join(output_dir, master_id)  # Create a subdirectory for the original image
        os.makedirs(image_output_dir, exist_ok=True)
        
        object_data = []
        
        for i, ann in enumerate(masks):
            object_id = f"{master_id}_{i}"  # Generate a unique ID for each object
            x, y, width, height = ann['bbox']  # Get the bounding box coordinates
            cropped_image = image[int(y):int(y+height), int(x):int(x+width)]  # Crop the image to the bounding box
            cropped_mask = ann['segmentation'][int(y):int(y+height), int(x):int(x+width)]  # Crop the corresponding mask
            segmented_object = cropped_image * cropped_mask[..., np.newaxis]  # Apply mask to isolate the object
            segmented_pil = Image.fromarray(segmented_object)  # Convert to PIL image
            object_filename = os.path.join(image_output_dir, f"{object_id}.png")  # Create file path for the object
            segmented_pil.save(object_filename)  # Save the segmented object image
            
            # Save metadata for each object
            object_data.append({
                "object_id": object_id,
                "master_id": master_id,
                "object_filename": object_filename,
                "area": ann['area'],
                "bbox": ann['bbox'],
            })
            
        return object_data

    def show_anns(self, anns):
        """
        Visualizes the masks on the original image.

        Parameters:
        - anns: A list of masks generated by the SAM model.
        """
        if len(anns) == 0:
            return
        
        # Sort the masks by their area in descending order
        sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)
        ax = plt.gca()
        ax.set_autoscale_on(False)
        
        # Create an image with the same size as the largest mask
        img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))
        img[:,:,3] = 0  # Set the alpha channel to 0 for transparency
        
        # Fill in the corresponding pixels in the new image with a random color
        for ann in sorted_anns:
            m = ann['segmentation']
            color_mask = np.concatenate([np.random.random(3), [0.35]])  # Generate a random color with transparency
            img[m] = color_mask
            
        ax.imshow(img)  # Display the image with masks

    def segment_and_save(self, input_path, output_dir=None):
        """
        Segments images in a directory or a single image into individual objects and saves the segmented objects and metadata.

        Parameters:
        - input_path: Path to the image file or directory containing images to be segmented.
        - output_dir: Directory to save the segmented objects and metadata. If not provided, uses the default output directory.
        """
        if output_dir is None:
            output_dir = self.output_dir  # Use default output directory if none is provided

        if os.path.isdir(input_path):  # Check if input is a directory
            image_files = [f for f in os.listdir(input_path) if os.path.isfile(os.path.join(input_path, f))]
            for image_file in image_files:
                image_path = os.path.join(input_path, image_file)
                self._process_image(image_path, output_dir)
        else:  # If input is a single image file
            self._process_image(input_path, output_dir)

    def _process_image(self, image_path, output_dir):
        """
        Processes a single image for segmentation.

        Parameters:
        - image_path: Path to the image file to be segmented.
        - output_dir: Directory to save the segmented objects and metadata.
        """
        image = cv2.imread(image_path)  # Read the image using OpenCV
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert the image to RGB format
        masks = self.mask_generator.generate(image)  # Generate masks for the image
        
        plt.figure(figsize=(10, 10)) 
        plt.imshow(image)
        self.show_anns(masks)  # Visualize the masks on the image
        
        master_id = str(uuid.uuid4())  # Generate a unique ID for the image
        object_data = self.extract_and_save_objects(image, masks, master_id, output_dir)  # Extract and save objects
        
        # Save metadata to a JSON file
        metadata_filename = os.path.join(output_dir, f"{master_id}_metadata.json")
        with open(metadata_filename, 'w') as f:
            json.dump(object_data, f, indent=4)

        print(f"Objects and metadata saved to {output_dir}")
        torch.cuda.empty_cache()  # Clear CUDA cache to free up memory


# Example usage:
pipeline = ImageSegmentationPipeline(sam_checkpoint="sam_vit_h_4b8939.pth")
pipeline.segment_and_save(r"C:\Users\adity\Documents\Cheetahs\wasserstoff\project_root\data\imput_images", output_dir=r"C:\Users\adity\Documents\Cheetahs\wasserstoff\project_root\data\segmented_objects")
